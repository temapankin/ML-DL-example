{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "894a98c5-eba5-48ea-9dc0-e0a33115bfd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM, Dense, Masking\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb0496-c7b8-4f44-8581-5a7124eb168e",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3db13763-ea41-43aa-a7d8-75503e98f261",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>degree</th>\n",
       "      <th>id</th>\n",
       "      <th>best_neighborID</th>\n",
       "      <th>pairs</th>\n",
       "      <th>array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>21.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>28.7</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>(34, 39)</td>\n",
       "      <td>[43128, 43355, 43430, 43500, 43570, 43676, 437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>21.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>41.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>(37, 38)</td>\n",
       "      <td>[44354, 44530, 44678, 44774, 44809, 44764, 446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>21.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>(38, 37)</td>\n",
       "      <td>[43005, 43036, 43031, 42931, 42764, 42572, 424...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>21.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>28.7</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>(39, 34)</td>\n",
       "      <td>[42023, 42148, 42356, 42565, 42759, 42938, 431...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>21.7</td>\n",
       "      <td>7.8</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>(40, 45)</td>\n",
       "      <td>[43793, 43827, 43837, 43826, 43814, 43781, 437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>19.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>641</td>\n",
       "      <td>640</td>\n",
       "      <td>(641, 640)</td>\n",
       "      <td>[42585, 42332]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>642</td>\n",
       "      <td>645</td>\n",
       "      <td>(642, 645)</td>\n",
       "      <td>[43060, 43095, 43139, 43199, 43290, 43324, 432...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>645</td>\n",
       "      <td>642</td>\n",
       "      <td>(645, 642)</td>\n",
       "      <td>[42998, 42914, 42820, 42724, 42687, 42709, 427...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>22.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>27.5</td>\n",
       "      <td>668</td>\n",
       "      <td>669</td>\n",
       "      <td>(668, 669)</td>\n",
       "      <td>[42829, 42919, 42964, 42972, 42993, 42977, 429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>19.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>669</td>\n",
       "      <td>668</td>\n",
       "      <td>(669, 668)</td>\n",
       "      <td>[43155, 43148, 43148, 43123, 43055, 42997, 429...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     temp_max  temp_min  humidity  precip  wind_speed  degree   id  \\\n",
       "34       21.5       7.6      37.9     0.0        24.1    28.7   34   \n",
       "37       21.7       8.4      41.2     0.0         7.9     9.4   37   \n",
       "38       21.7       7.3      35.2     0.0         6.5     5.0   38   \n",
       "39       21.5       7.6      37.9     0.0        24.1    28.7   39   \n",
       "40       21.7       7.8      35.6     0.0        23.8    28.4   40   \n",
       "..        ...       ...       ...     ...         ...     ...  ...   \n",
       "641      19.9       4.5      26.6     0.0        23.0    31.2  641   \n",
       "642      22.0       7.5      23.1     0.0        25.2    25.1  642   \n",
       "645      22.0       7.5      23.1     0.0        25.2    25.1  645   \n",
       "668      22.8       3.4      24.5     0.0        11.2    27.5  668   \n",
       "669      19.9       4.3      27.0     0.0        23.0    29.2  669   \n",
       "\n",
       "     best_neighborID       pairs  \\\n",
       "34                39    (34, 39)   \n",
       "37                38    (37, 38)   \n",
       "38                37    (38, 37)   \n",
       "39                34    (39, 34)   \n",
       "40                45    (40, 45)   \n",
       "..               ...         ...   \n",
       "641              640  (641, 640)   \n",
       "642              645  (642, 645)   \n",
       "645              642  (645, 642)   \n",
       "668              669  (668, 669)   \n",
       "669              668  (669, 668)   \n",
       "\n",
       "                                                 array  \n",
       "34   [43128, 43355, 43430, 43500, 43570, 43676, 437...  \n",
       "37   [44354, 44530, 44678, 44774, 44809, 44764, 446...  \n",
       "38   [43005, 43036, 43031, 42931, 42764, 42572, 424...  \n",
       "39   [42023, 42148, 42356, 42565, 42759, 42938, 431...  \n",
       "40   [43793, 43827, 43837, 43826, 43814, 43781, 437...  \n",
       "..                                                 ...  \n",
       "641                                     [42585, 42332]  \n",
       "642  [43060, 43095, 43139, 43199, 43290, 43324, 432...  \n",
       "645  [42998, 42914, 42820, 42724, 42687, 42709, 427...  \n",
       "668  [42829, 42919, 42964, 42972, 42993, 42977, 429...  \n",
       "669  [43155, 43148, 43148, 43123, 43055, 42997, 429...  \n",
       "\n",
       "[74 rows x 10 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('Lines.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2b999dc2-8c7a-4f02-b19d-123f9c8f763d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = df[\"array\"].tolist()\n",
    "\n",
    "raw_inputs = []\n",
    "for i in range(len(data)):\n",
    "    raw_inputs.append(data[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "17257c39-27e9-403d-bade-aad3747b2288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare input and target datasets\n",
    "x, y = [], []\n",
    "for i in range(len(raw_inputs)):\n",
    "    x.append(raw_inputs[i][:-1])\n",
    "    y.append(raw_inputs[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3d9fb868-cdc8-4a61-9bbc-a2a7dedd9733",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43128, 43355, 43430, ...,     0,     0,     0],\n",
       "       [44354, 44530, 44678, ...,     0,     0,     0],\n",
       "       [43005, 43036, 43031, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [42998, 42914, 42820, ...,     0,     0,     0],\n",
       "       [42829, 42919, 42964, ...,     0,     0,     0],\n",
       "       [43155, 43148, 43148, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padded_inputs = tf.keras.utils.pad_sequences(x, padding=\"post\")\n",
    "x_padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b271996b-4525-4741-8712-6107369a2f81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "X = x_padded_inputs.reshape((x_padded_inputs.shape[0], x_padded_inputs.shape[1], n_features))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4a8ba01f-b987-4cfb-8d32-9fe45c56a5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74, 56, 1), (74,))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9eced2b7-28e7-49c2-a50f-a587992b3420",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55, 56, 1), (55,), (19, 56, 1), (19,))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = X[:55], y[:55]\n",
    "#X_val, y_val = X[50:55], y[50:55]\n",
    "X_test, y_test = X[55:], y[55:]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape #X_val.shape, y_val.shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428936ea-c120-4521-a90c-3ea394f30ec5",
   "metadata": {},
   "source": [
    "# Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "783119a9-317b-4f22-9abd-2dd3a17b5aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model1 = keras.Sequential(layers.Embedding(input_dim=46281, output_dim=16, mask_zero=True, input_length=56))\n",
    "\n",
    "model1 = keras.Sequential()\n",
    "model1.add(Masking(mask_value=0.0, input_shape = (56,1))) # masking to ignore padded 0\n",
    "model1.add(layers.LSTM(50, # check info on units here https://tung2389.github.io/coding-note/unitslstm\n",
    "                      activation='relu'))\n",
    "model1.add(Dense(8, 'relu'))\n",
    "model1.add(Dense(1, 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "65129de8-6ec9-432d-95fa-762ba2e2ddb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.layers.core.masking.Masking at 0x2c75bab50>,\n",
       " <keras.src.layers.rnn.lstm.LSTM at 0x2c6f16c10>,\n",
       " <keras.src.layers.core.dense.Dense at 0x2c6f30c90>,\n",
       " <keras.src.layers.core.dense.Dense at 0x2c75e3a50>]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cad403b8-da26-4eb9-86c2-22d73eb4f425",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_20 (Masking)        (None, 56, 1)             0         \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 50)                10400     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 8)                 408       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10817 (42.25 KB)\n",
      "Trainable params: 10817 (42.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "df5c879b-9c06-4e53-b320-9091545841df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a7cf6759-881c-4f27-a637-c26b34df5bee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 182ms/step - loss: 2229530112.0000 - accuracy: 0.0000e+00 - val_loss: 2126816000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2293500928.0000 - accuracy: 0.0000e+00 - val_loss: 1907199488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2011353216.0000 - accuracy: 0.0000e+00 - val_loss: 1896123264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1875161472.0000 - accuracy: 0.0000e+00 - val_loss: 1783183488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1854744192.0000 - accuracy: 0.0000e+00 - val_loss: 1747522432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1755726208.0000 - accuracy: 0.0000e+00 - val_loss: 2188648192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2013984896.0000 - accuracy: 0.0000e+00 - val_loss: 1758825344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1576210432.0000 - accuracy: 0.0000e+00 - val_loss: 1619565312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1849769600.0000 - accuracy: 0.0000e+00 - val_loss: 2009104896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2359363584.0000 - accuracy: 0.0000e+00 - val_loss: 1817084032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1597655936.0000 - accuracy: 0.0000e+00 - val_loss: 1537059328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1189925760.0000 - accuracy: 0.0000e+00 - val_loss: 1530962560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1173645440.0000 - accuracy: 0.0000e+00 - val_loss: 1553405312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1303446272.0000 - accuracy: 0.0000e+00 - val_loss: 1579632128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1323241344.0000 - accuracy: 0.0000e+00 - val_loss: 1579600000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1303143168.0000 - accuracy: 0.0000e+00 - val_loss: 1544665600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1353273856.0000 - accuracy: 0.0000e+00 - val_loss: 1523302528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1258047872.0000 - accuracy: 0.0000e+00 - val_loss: 1497659392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1189848192.0000 - accuracy: 0.0000e+00 - val_loss: 1480240128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1134145024.0000 - accuracy: 0.0000e+00 - val_loss: 1477590656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1175996928.0000 - accuracy: 0.0000e+00 - val_loss: 1414049408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 932917440.0000 - accuracy: 0.0000e+00 - val_loss: 1407513344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1011744960.0000 - accuracy: 0.0000e+00 - val_loss: 1202629504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 764858112.0000 - accuracy: 0.0000e+00 - val_loss: 1206801536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 814339264.0000 - accuracy: 0.0000e+00 - val_loss: 1205005824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 851190784.0000 - accuracy: 0.0000e+00 - val_loss: 1199199104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 788818752.0000 - accuracy: 0.0000e+00 - val_loss: 1185643392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 751885952.0000 - accuracy: 0.0000e+00 - val_loss: 1168220416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 709480640.0000 - accuracy: 0.0000e+00 - val_loss: 1169867264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 726765696.0000 - accuracy: 0.0000e+00 - val_loss: 1289231232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 744572736.0000 - accuracy: 0.0000e+00 - val_loss: 1098190976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 690353472.0000 - accuracy: 0.0000e+00 - val_loss: 1155680000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 818180480.0000 - accuracy: 0.0000e+00 - val_loss: 1114298368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 741339072.0000 - accuracy: 0.0000e+00 - val_loss: 1088321664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 875599616.0000 - accuracy: 0.0000e+00 - val_loss: 1441005568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1419506048.0000 - accuracy: 0.0000e+00 - val_loss: 1433710720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1419389056.0000 - accuracy: 0.0000e+00 - val_loss: 1397323264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1399554048.0000 - accuracy: 0.0000e+00 - val_loss: 1420119168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1465645568.0000 - accuracy: 0.0000e+00 - val_loss: 1485419008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1475490688.0000 - accuracy: 0.0000e+00 - val_loss: 1422235776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1440742912.0000 - accuracy: 0.0000e+00 - val_loss: 1440191360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1399456640.0000 - accuracy: 0.0000e+00 - val_loss: 1450610944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1393058176.0000 - accuracy: 0.0000e+00 - val_loss: 1448910080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1324118144.0000 - accuracy: 0.0000e+00 - val_loss: 1644121344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1287410176.0000 - accuracy: 0.0000e+00 - val_loss: 1324450432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1325582720.0000 - accuracy: 0.0000e+00 - val_loss: 1295328896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1358688128.0000 - accuracy: 0.0000e+00 - val_loss: 1215933184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1294935296.0000 - accuracy: 0.0000e+00 - val_loss: 1117197696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1351958912.0000 - accuracy: 0.0000e+00 - val_loss: 1102466176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1301199104.0000 - accuracy: 0.0000e+00 - val_loss: 1094852608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1261076224.0000 - accuracy: 0.0000e+00 - val_loss: 1241168768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1273614208.0000 - accuracy: 0.0000e+00 - val_loss: 1107693696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1328553984.0000 - accuracy: 0.0000e+00 - val_loss: 1142603904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1188869760.0000 - accuracy: 0.0000e+00 - val_loss: 1032460032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1185710080.0000 - accuracy: 0.0000e+00 - val_loss: 1077900928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1133205376.0000 - accuracy: 0.0000e+00 - val_loss: 1145473920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1068664640.0000 - accuracy: 0.0000e+00 - val_loss: 1090731776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1034846592.0000 - accuracy: 0.0000e+00 - val_loss: 1156392704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 937537984.0000 - accuracy: 0.0000e+00 - val_loss: 1052212160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 836212480.0000 - accuracy: 0.0000e+00 - val_loss: 881225728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 807972864.0000 - accuracy: 0.0000e+00 - val_loss: 855003904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 773980032.0000 - accuracy: 0.0000e+00 - val_loss: 604554880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 677469952.0000 - accuracy: 0.0000e+00 - val_loss: 848483264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 718871296.0000 - accuracy: 0.0000e+00 - val_loss: 792425024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 690561024.0000 - accuracy: 0.0000e+00 - val_loss: 731859520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 655144512.0000 - accuracy: 0.0000e+00 - val_loss: 796622464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 464781408.0000 - accuracy: 0.0000e+00 - val_loss: 794920192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 502375040.0000 - accuracy: 0.0000e+00 - val_loss: 699042880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 420344544.0000 - accuracy: 0.0000e+00 - val_loss: 597477312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 499929216.0000 - accuracy: 0.0000e+00 - val_loss: 640391616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 431283840.0000 - accuracy: 0.0000e+00 - val_loss: 560126272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 397554688.0000 - accuracy: 0.0000e+00 - val_loss: 653583104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 425415296.0000 - accuracy: 0.0000e+00 - val_loss: 310200608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 477537888.0000 - accuracy: 0.0000e+00 - val_loss: 374935424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 448341984.0000 - accuracy: 0.0000e+00 - val_loss: 409657312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 409834688.0000 - accuracy: 0.0000e+00 - val_loss: 377036896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 409088320.0000 - accuracy: 0.0000e+00 - val_loss: 221528976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 391444096.0000 - accuracy: 0.0000e+00 - val_loss: 349138432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 568469568.0000 - accuracy: 0.0000e+00 - val_loss: 560911872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/300\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 591512000.0000 - accuracy: 0.0000e+00 - val_loss: 341806560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1173468672.0000 - accuracy: 0.0000e+00 - val_loss: 550194752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 614859200.0000 - accuracy: 0.0000e+00 - val_loss: 581890304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 593174336.0000 - accuracy: 0.0000e+00 - val_loss: 204830160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 434894368.0000 - accuracy: 0.0000e+00 - val_loss: 421359488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 367946208.0000 - accuracy: 0.0000e+00 - val_loss: 383747424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 370048832.0000 - accuracy: 0.0000e+00 - val_loss: 712884544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 418338112.0000 - accuracy: 0.0000e+00 - val_loss: 804296128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 473065376.0000 - accuracy: 0.0000e+00 - val_loss: 921597376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 380505984.0000 - accuracy: 0.0000e+00 - val_loss: 940361920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 368887584.0000 - accuracy: 0.0000e+00 - val_loss: 1091840512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 401167776.0000 - accuracy: 0.0000e+00 - val_loss: 946007488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 354539904.0000 - accuracy: 0.0000e+00 - val_loss: 889976256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 361534752.0000 - accuracy: 0.0000e+00 - val_loss: 842119104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 378082176.0000 - accuracy: 0.0000e+00 - val_loss: 837607232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 391555040.0000 - accuracy: 0.0000e+00 - val_loss: 955386496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 398777984.0000 - accuracy: 0.0000e+00 - val_loss: 939717376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 493117664.0000 - accuracy: 0.0000e+00 - val_loss: 954124480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 468171040.0000 - accuracy: 0.0000e+00 - val_loss: 1007146368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 419392928.0000 - accuracy: 0.0000e+00 - val_loss: 985358592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 379919040.0000 - accuracy: 0.0000e+00 - val_loss: 1070187968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 515476864.0000 - accuracy: 0.0000e+00 - val_loss: 1050549824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 358502816.0000 - accuracy: 0.0000e+00 - val_loss: 997169728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 348749952.0000 - accuracy: 0.0000e+00 - val_loss: 981554368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 584571200.0000 - accuracy: 0.0000e+00 - val_loss: 860732416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 401061504.0000 - accuracy: 0.0000e+00 - val_loss: 690292544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 772546496.0000 - accuracy: 0.0000e+00 - val_loss: 3065459968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 418409856.0000 - accuracy: 0.0000e+00 - val_loss: 665078208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1588775424.0000 - accuracy: 0.0000e+00 - val_loss: 622915584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 554179968.0000 - accuracy: 0.0000e+00 - val_loss: 646693120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 275126304.0000 - accuracy: 0.0000e+00 - val_loss: 1571269504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 190691248.0000 - accuracy: 0.0000e+00 - val_loss: 671413632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 284746112.0000 - accuracy: 0.0000e+00 - val_loss: 1054295680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 328402688.0000 - accuracy: 0.0000e+00 - val_loss: 953069952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 327694624.0000 - accuracy: 0.0000e+00 - val_loss: 810079872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 403893888.0000 - accuracy: 0.0000e+00 - val_loss: 818871296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 378224352.0000 - accuracy: 0.0000e+00 - val_loss: 468805440.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 505385088.0000 - accuracy: 0.0000e+00 - val_loss: 290946240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 529395168.0000 - accuracy: 0.0000e+00 - val_loss: 347955392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1068350656.0000 - accuracy: 0.0000e+00 - val_loss: 292743392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 725563968.0000 - accuracy: 0.0000e+00 - val_loss: 272680480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 528396480.0000 - accuracy: 0.0000e+00 - val_loss: 432664384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 389924832.0000 - accuracy: 0.0000e+00 - val_loss: 353163744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 452102784.0000 - accuracy: 0.0000e+00 - val_loss: 543253888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 461329952.0000 - accuracy: 0.0000e+00 - val_loss: 462571200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 388454432.0000 - accuracy: 0.0000e+00 - val_loss: 363733376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 530831552.0000 - accuracy: 0.0000e+00 - val_loss: 421921920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 547940928.0000 - accuracy: 0.0000e+00 - val_loss: 419808256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 478958208.0000 - accuracy: 0.0000e+00 - val_loss: 507995520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 506288512.0000 - accuracy: 0.0000e+00 - val_loss: 472536896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 514168192.0000 - accuracy: 0.0000e+00 - val_loss: 337382688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 470863488.0000 - accuracy: 0.0000e+00 - val_loss: 412214240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 480694656.0000 - accuracy: 0.0000e+00 - val_loss: 547971584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 471918880.0000 - accuracy: 0.0000e+00 - val_loss: 466712480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 482787808.0000 - accuracy: 0.0000e+00 - val_loss: 359628512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 459961632.0000 - accuracy: 0.0000e+00 - val_loss: 305054496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 354573280.0000 - accuracy: 0.0000e+00 - val_loss: 373032032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 403976736.0000 - accuracy: 0.0000e+00 - val_loss: 407734400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 556896000.0000 - accuracy: 0.0000e+00 - val_loss: 473672608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 442848640.0000 - accuracy: 0.0000e+00 - val_loss: 436746848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 422246368.0000 - accuracy: 0.0000e+00 - val_loss: 457450272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 447116672.0000 - accuracy: 0.0000e+00 - val_loss: 712809920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 454827648.0000 - accuracy: 0.0000e+00 - val_loss: 717902976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 409464192.0000 - accuracy: 0.0000e+00 - val_loss: 592663808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 319490976.0000 - accuracy: 0.0000e+00 - val_loss: 737896896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 437600800.0000 - accuracy: 0.0000e+00 - val_loss: 581878848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 393611808.0000 - accuracy: 0.0000e+00 - val_loss: 891173632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 344640704.0000 - accuracy: 0.0000e+00 - val_loss: 638249536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 458632192.0000 - accuracy: 0.0000e+00 - val_loss: 751404288.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 400052736.0000 - accuracy: 0.0000e+00 - val_loss: 591550272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 390803744.0000 - accuracy: 0.0000e+00 - val_loss: 628288768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 508041184.0000 - accuracy: 0.0000e+00 - val_loss: 1306875776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 303721152.0000 - accuracy: 0.0000e+00 - val_loss: 811462464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 385268256.0000 - accuracy: 0.0000e+00 - val_loss: 784702272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 331961088.0000 - accuracy: 0.0000e+00 - val_loss: 1048402688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 433252992.0000 - accuracy: 0.0000e+00 - val_loss: 763506176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 956638464.0000 - accuracy: 0.0000e+00 - val_loss: 1866385024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 789032768.0000 - accuracy: 0.0000e+00 - val_loss: 1958159872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1445994496.0000 - accuracy: 0.0000e+00 - val_loss: 1792244992.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 829856512.0000 - accuracy: 0.0000e+00 - val_loss: 644464832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 762400192.0000 - accuracy: 0.0000e+00 - val_loss: 948652096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 491824160.0000 - accuracy: 0.0000e+00 - val_loss: 533070208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 404939360.0000 - accuracy: 0.0000e+00 - val_loss: 477218496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 441852000.0000 - accuracy: 0.0000e+00 - val_loss: 676630784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 560100544.0000 - accuracy: 0.0000e+00 - val_loss: 515357312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 514076576.0000 - accuracy: 0.0000e+00 - val_loss: 520739008.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 458542624.0000 - accuracy: 0.0000e+00 - val_loss: 504968736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 489935968.0000 - accuracy: 0.0000e+00 - val_loss: 669778560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 450638304.0000 - accuracy: 0.0000e+00 - val_loss: 643135424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 554013760.0000 - accuracy: 0.0000e+00 - val_loss: 576981760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 430041088.0000 - accuracy: 0.0000e+00 - val_loss: 434191072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 626793472.0000 - accuracy: 0.0000e+00 - val_loss: 473603200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 558171200.0000 - accuracy: 0.0000e+00 - val_loss: 790611904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 687831040.0000 - accuracy: 0.0000e+00 - val_loss: 605447424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 619302464.0000 - accuracy: 0.0000e+00 - val_loss: 606334016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 585847168.0000 - accuracy: 0.0000e+00 - val_loss: 698958016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 581225024.0000 - accuracy: 0.0000e+00 - val_loss: 452961760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 486870912.0000 - accuracy: 0.0000e+00 - val_loss: 475135712.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 593464512.0000 - accuracy: 0.0000e+00 - val_loss: 364522144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 670594688.0000 - accuracy: 0.0000e+00 - val_loss: 438732064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 473213216.0000 - accuracy: 0.0000e+00 - val_loss: 591910720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 498198400.0000 - accuracy: 0.0000e+00 - val_loss: 492295904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 470108128.0000 - accuracy: 0.0000e+00 - val_loss: 429738272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 417010880.0000 - accuracy: 0.0000e+00 - val_loss: 413465728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 449541120.0000 - accuracy: 0.0000e+00 - val_loss: 349181632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 557807040.0000 - accuracy: 0.0000e+00 - val_loss: 361136192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 471486656.0000 - accuracy: 0.0000e+00 - val_loss: 426205600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 435066848.0000 - accuracy: 0.0000e+00 - val_loss: 483874816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 485844096.0000 - accuracy: 0.0000e+00 - val_loss: 405727328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 454233472.0000 - accuracy: 0.0000e+00 - val_loss: 345831712.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 406077536.0000 - accuracy: 0.0000e+00 - val_loss: 346721056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 439071968.0000 - accuracy: 0.0000e+00 - val_loss: 344751232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 451376928.0000 - accuracy: 0.0000e+00 - val_loss: 404231296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 338241824.0000 - accuracy: 0.0000e+00 - val_loss: 459725088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 337129312.0000 - accuracy: 0.0000e+00 - val_loss: 426869024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 344796544.0000 - accuracy: 0.0000e+00 - val_loss: 391170368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 326550624.0000 - accuracy: 0.0000e+00 - val_loss: 474185920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 273171232.0000 - accuracy: 0.0000e+00 - val_loss: 394306944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 382248928.0000 - accuracy: 0.0000e+00 - val_loss: 436202496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 224457328.0000 - accuracy: 0.0000e+00 - val_loss: 417595616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 394964384.0000 - accuracy: 0.0000e+00 - val_loss: 369656032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 427167744.0000 - accuracy: 0.0000e+00 - val_loss: 369510784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 388473664.0000 - accuracy: 0.0000e+00 - val_loss: 367357504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 411727968.0000 - accuracy: 0.0000e+00 - val_loss: 375247776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 403787392.0000 - accuracy: 0.0000e+00 - val_loss: 357746464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 363271904.0000 - accuracy: 0.0000e+00 - val_loss: 496383872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 277665920.0000 - accuracy: 0.0000e+00 - val_loss: 360484672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 329033440.0000 - accuracy: 0.0000e+00 - val_loss: 346012384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 445257248.0000 - accuracy: 0.0000e+00 - val_loss: 343252384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 351462944.0000 - accuracy: 0.0000e+00 - val_loss: 533538112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 657362496.0000 - accuracy: 0.0000e+00 - val_loss: 608680512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 615704000.0000 - accuracy: 0.0000e+00 - val_loss: 489288800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 654516032.0000 - accuracy: 0.0000e+00 - val_loss: 472911968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 345465408.0000 - accuracy: 0.0000e+00 - val_loss: 500523712.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 267953664.0000 - accuracy: 0.0000e+00 - val_loss: 484273568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 297947264.0000 - accuracy: 0.0000e+00 - val_loss: 435915360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 438920832.0000 - accuracy: 0.0000e+00 - val_loss: 408366784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 260734624.0000 - accuracy: 0.0000e+00 - val_loss: 504248096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 289997024.0000 - accuracy: 0.0000e+00 - val_loss: 359630592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 347019648.0000 - accuracy: 0.0000e+00 - val_loss: 356976672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 334342784.0000 - accuracy: 0.0000e+00 - val_loss: 356254208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 329417184.0000 - accuracy: 0.0000e+00 - val_loss: 352714784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 281277984.0000 - accuracy: 0.0000e+00 - val_loss: 426840800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 317268256.0000 - accuracy: 0.0000e+00 - val_loss: 460483392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 345693792.0000 - accuracy: 0.0000e+00 - val_loss: 443186176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 356607232.0000 - accuracy: 0.0000e+00 - val_loss: 353058336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 312080256.0000 - accuracy: 0.0000e+00 - val_loss: 342644928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 326690432.0000 - accuracy: 0.0000e+00 - val_loss: 364404480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 318973952.0000 - accuracy: 0.0000e+00 - val_loss: 334482816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 304201792.0000 - accuracy: 0.0000e+00 - val_loss: 315024192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 348221152.0000 - accuracy: 0.0000e+00 - val_loss: 409013792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 344681440.0000 - accuracy: 0.0000e+00 - val_loss: 326482112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 314080992.0000 - accuracy: 0.0000e+00 - val_loss: 353333760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 324343776.0000 - accuracy: 0.0000e+00 - val_loss: 285799456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 334381184.0000 - accuracy: 0.0000e+00 - val_loss: 292019968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 322500288.0000 - accuracy: 0.0000e+00 - val_loss: 292294112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 315658912.0000 - accuracy: 0.0000e+00 - val_loss: 294313376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 314903136.0000 - accuracy: 0.0000e+00 - val_loss: 314562272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 351825920.0000 - accuracy: 0.0000e+00 - val_loss: 276605792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 333851840.0000 - accuracy: 0.0000e+00 - val_loss: 271456736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 328551648.0000 - accuracy: 0.0000e+00 - val_loss: 269760544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 337180544.0000 - accuracy: 0.0000e+00 - val_loss: 264667280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 314107168.0000 - accuracy: 0.0000e+00 - val_loss: 259655408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 311592192.0000 - accuracy: 0.0000e+00 - val_loss: 254735872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 306696064.0000 - accuracy: 0.0000e+00 - val_loss: 250163104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 293805088.0000 - accuracy: 0.0000e+00 - val_loss: 245969040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 293818144.0000 - accuracy: 0.0000e+00 - val_loss: 242157776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 315112480.0000 - accuracy: 0.0000e+00 - val_loss: 289973568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 311152608.0000 - accuracy: 0.0000e+00 - val_loss: 293202144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 308353856.0000 - accuracy: 0.0000e+00 - val_loss: 282852608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 304833440.0000 - accuracy: 0.0000e+00 - val_loss: 379607552.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 301513728.0000 - accuracy: 0.0000e+00 - val_loss: 278767520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 298517824.0000 - accuracy: 0.0000e+00 - val_loss: 280876384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 283600928.0000 - accuracy: 0.0000e+00 - val_loss: 278169984.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 280633664.0000 - accuracy: 0.0000e+00 - val_loss: 275665760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 277972640.0000 - accuracy: 0.0000e+00 - val_loss: 273424736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 276631136.0000 - accuracy: 0.0000e+00 - val_loss: 271169728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 277883680.0000 - accuracy: 0.0000e+00 - val_loss: 268985248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 311303648.0000 - accuracy: 0.0000e+00 - val_loss: 254922640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 285589792.0000 - accuracy: 0.0000e+00 - val_loss: 325826784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 296561888.0000 - accuracy: 0.0000e+00 - val_loss: 426523552.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 296030112.0000 - accuracy: 0.0000e+00 - val_loss: 317919872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 278111936.0000 - accuracy: 0.0000e+00 - val_loss: 406456320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 284346272.0000 - accuracy: 0.0000e+00 - val_loss: 295642912.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 259656608.0000 - accuracy: 0.0000e+00 - val_loss: 299109312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 258274464.0000 - accuracy: 0.0000e+00 - val_loss: 297664416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 255403840.0000 - accuracy: 0.0000e+00 - val_loss: 296584736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 263329008.0000 - accuracy: 0.0000e+00 - val_loss: 295260768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 260630112.0000 - accuracy: 0.0000e+00 - val_loss: 294040896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 267304128.0000 - accuracy: 0.0000e+00 - val_loss: 281888800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 314000608.0000 - accuracy: 0.0000e+00 - val_loss: 279823968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 361304288.0000 - accuracy: 0.0000e+00 - val_loss: 278508928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 334608640.0000 - accuracy: 0.0000e+00 - val_loss: 277364960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 284764160.0000 - accuracy: 0.0000e+00 - val_loss: 276153344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 274778816.0000 - accuracy: 0.0000e+00 - val_loss: 274965792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 272505440.0000 - accuracy: 0.0000e+00 - val_loss: 272000608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 270509952.0000 - accuracy: 0.0000e+00 - val_loss: 270753952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 268691840.0000 - accuracy: 0.0000e+00 - val_loss: 271130176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 250091936.0000 - accuracy: 0.0000e+00 - val_loss: 270009856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 264721504.0000 - accuracy: 0.0000e+00 - val_loss: 268891328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 250004528.0000 - accuracy: 0.0000e+00 - val_loss: 267721792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 239755024.0000 - accuracy: 0.0000e+00 - val_loss: 266491920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 237472304.0000 - accuracy: 0.0000e+00 - val_loss: 265233808.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 235767712.0000 - accuracy: 0.0000e+00 - val_loss: 264001680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 232336656.0000 - accuracy: 0.0000e+00 - val_loss: 262812720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 229760576.0000 - accuracy: 0.0000e+00 - val_loss: 261689760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 227300624.0000 - accuracy: 0.0000e+00 - val_loss: 260649376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 225177696.0000 - accuracy: 0.0000e+00 - val_loss: 259689792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 222702352.0000 - accuracy: 0.0000e+00 - val_loss: 258820848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 217454864.0000 - accuracy: 0.0000e+00 - val_loss: 190210208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 228755616.0000 - accuracy: 0.0000e+00 - val_loss: 292135136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 212171408.0000 - accuracy: 0.0000e+00 - val_loss: 305208352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/300\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 191455312.0000 - accuracy: 0.0000e+00 - val_loss: 304581120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 198462576.0000 - accuracy: 0.0000e+00 - val_loss: 180258192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 295918400.0000 - accuracy: 0.0000e+00 - val_loss: 184100192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 295235040.0000 - accuracy: 0.0000e+00 - val_loss: 203901488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 369977440.0000 - accuracy: 0.0000e+00 - val_loss: 182811856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 405915040.0000 - accuracy: 0.0000e+00 - val_loss: 179174944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 383759392.0000 - accuracy: 0.0000e+00 - val_loss: 178695328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 376450912.0000 - accuracy: 0.0000e+00 - val_loss: 216579792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 357046240.0000 - accuracy: 0.0000e+00 - val_loss: 215803248.0000 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=300,\n",
    "    verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f192d29a-dd38-446c-8ddd-9eeece91d3dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_sequence = X_test[0]\n",
    "input_sequence = input_sequence.reshape((1, x_padded_inputs.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7eff439e-d253-4864-80b8-fcbc98316e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#input_sequence = X_train[-10]\n",
    "#predicted_value = model1.predict(input_sequence)[0][-1]\n",
    "#print(\"Predicted Value:\", round(predicted_value, ndigits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0cadaa9d-2986-4836-b7dc-0fd4528f1b09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2c7bd4860> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2c7bd4860> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 118ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[37346.26]], dtype=float32)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f79be8fc-72d3-4862-867d-58db56d07278",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Predictions</th>\n",
       "      <th>Actuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17322.0</td>\n",
       "      <td>42023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63856.0</td>\n",
       "      <td>43005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20536.0</td>\n",
       "      <td>44354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19197.0</td>\n",
       "      <td>43128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43582.0</td>\n",
       "      <td>45136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39470.0</td>\n",
       "      <td>43793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47079.0</td>\n",
       "      <td>45029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45146.0</td>\n",
       "      <td>44357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32633.0</td>\n",
       "      <td>44155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39646.0</td>\n",
       "      <td>44404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29238.0</td>\n",
       "      <td>43028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36796.0</td>\n",
       "      <td>42570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19838.0</td>\n",
       "      <td>44018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19046.0</td>\n",
       "      <td>42582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36487.0</td>\n",
       "      <td>41897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>58855.0</td>\n",
       "      <td>43829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35817.0</td>\n",
       "      <td>43131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>35621.0</td>\n",
       "      <td>43916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44066.0</td>\n",
       "      <td>42885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>46372.0</td>\n",
       "      <td>44204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>37045.0</td>\n",
       "      <td>44840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>35445.0</td>\n",
       "      <td>44086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>35759.0</td>\n",
       "      <td>43443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40487.0</td>\n",
       "      <td>43660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>54464.0</td>\n",
       "      <td>44958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40446.0</td>\n",
       "      <td>43890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27867.0</td>\n",
       "      <td>44046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12051.0</td>\n",
       "      <td>44581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>26840.0</td>\n",
       "      <td>42510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32004.0</td>\n",
       "      <td>43307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4727.0</td>\n",
       "      <td>42226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4713.0</td>\n",
       "      <td>41711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>22096.0</td>\n",
       "      <td>44652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>11097.0</td>\n",
       "      <td>43854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>42506.0</td>\n",
       "      <td>42483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>42776.0</td>\n",
       "      <td>43222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>68393.0</td>\n",
       "      <td>44031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37056.0</td>\n",
       "      <td>43471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>45197.0</td>\n",
       "      <td>43182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>28778.0</td>\n",
       "      <td>45192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>13149.0</td>\n",
       "      <td>41916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>21513.0</td>\n",
       "      <td>42769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20133.0</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>43021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>43021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>23431.0</td>\n",
       "      <td>44148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>45431.0</td>\n",
       "      <td>43876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>43433.0</td>\n",
       "      <td>43932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>43433.0</td>\n",
       "      <td>43145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>44060.0</td>\n",
       "      <td>43049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>39591.0</td>\n",
       "      <td>43953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>46228.0</td>\n",
       "      <td>43217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>40308.0</td>\n",
       "      <td>40961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>37321.0</td>\n",
       "      <td>43071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>37384.0</td>\n",
       "      <td>42733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Train Predictions  Actuals\n",
       "0             17322.0    42023\n",
       "1             63856.0    43005\n",
       "2             20536.0    44354\n",
       "3             19197.0    43128\n",
       "4             43582.0    45136\n",
       "5             39470.0    43793\n",
       "6             47079.0    45029\n",
       "7             45146.0    44357\n",
       "8             32633.0    44155\n",
       "9             39646.0    44404\n",
       "10            29238.0    43028\n",
       "11            36796.0    42570\n",
       "12            19838.0    44018\n",
       "13            19046.0    42582\n",
       "14            36487.0    41897\n",
       "15            58855.0    43829\n",
       "16            35817.0    43131\n",
       "17            35621.0    43916\n",
       "18            44066.0    42885\n",
       "19            46372.0    44204\n",
       "20            37045.0    44840\n",
       "21            35445.0    44086\n",
       "22            35759.0    43443\n",
       "23            40487.0    43660\n",
       "24            54464.0    44958\n",
       "25            40446.0    43890\n",
       "26            27867.0    44046\n",
       "27            12051.0    44581\n",
       "28            26840.0    42510\n",
       "29            32004.0    43307\n",
       "30             4727.0    42226\n",
       "31             4713.0    41711\n",
       "32            22096.0    44652\n",
       "33            11097.0    43854\n",
       "34            42506.0    42483\n",
       "35            42776.0    43222\n",
       "36            68393.0    44031\n",
       "37            37056.0    43471\n",
       "38            45197.0    43182\n",
       "39            28778.0    45192\n",
       "40            13149.0    41916\n",
       "41            21513.0    42769\n",
       "42            20133.0    43200\n",
       "43                1.0    43021\n",
       "44                1.0    43021\n",
       "45            23431.0    44148\n",
       "46            45431.0    43876\n",
       "47            43433.0    43932\n",
       "48            43433.0    43145\n",
       "49            44060.0    43049\n",
       "50            39591.0    43953\n",
       "51            46228.0    43217\n",
       "52            40308.0    40961\n",
       "53            37321.0    43071\n",
       "54            37384.0    42733"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions = model1.predict(X_train).flatten()\n",
    "train_results = pd.DataFrame(data={'Train Predictions':np.round(train_predictions), 'Actuals':y_train})\n",
    "train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e5e5d-d6b9-46ed-8b8a-d7b4d558bf2f",
   "metadata": {},
   "source": [
    "**Next steps:**\n",
    "1. More Data (!)\n",
    "2. Normalization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
